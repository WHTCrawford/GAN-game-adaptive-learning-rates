
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{GALR presentation}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    We first load the packages we are using, notably TensorFlow.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{tensorflow} \PY{k+kn}{as} \PY{n+nn}{tf}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
\end{Verbatim}


    We then specify some of the hyperparameters of the model. The structure
of the learning is as follows. We randomly generate four lots of the
parameter \(\phi\) and four lots of \(\gamma\). We then overwrite the
first \(\phi\) with 0. This gives sixteen combinations of \(\phi\) and
\(\gamma\), a quarter of which have \(\phi = 0\). This was done because
\(\phi = 0\) corresponds to standard learning rates which we wanted to
compare to game adaptive learning rates. Then for each step from 1 to
\textbf{number\_of\_epochs} we generate \textbf{batch\_size} real
samples and \textbf{batch\_size} fake samples and used these to carry
out simulateneous minibatch gradient descent. In our experiments we
iterated this process many times in order to collect over 10,000
parameter combinations in total, for simplicity we display the code for
a single group of the sixteen parameter combinations.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{gamma\PYZus{}vec} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.0000001}\PY{p}{,}\PY{l+m+mf}{0.1}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{)}
        \PY{n}{phi\PYZus{}vec} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}
        \PY{n}{phi\PYZus{}vec}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{=} \PY{l+m+mf}{0.0}
        
        \PY{n}{number\PYZus{}of\PYZus{}epochs} \PY{o}{=} \PY{l+m+mi}{100000}
        \PY{n}{batch\PYZus{}size} \PY{o}{=} \PY{l+m+mi}{1000}
\end{Verbatim}


    We now define the mean and standard deviation of the Gaussian
distribition which \(G\) is attempting to learn.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{n}{real\PYZus{}mean} \PY{o}{=} \PY{l+m+mi}{6}
        \PY{n}{real\PYZus{}sd} \PY{o}{=} \PY{l+m+mi}{1}
\end{Verbatim}


    We now create the discriminator and the generator, which are feed
forward neural networks. \(G\) has a single hidden layer with a tanh
activation function, wheras \(D\) has two hidden layers. Note we run the
output of \(D\) through the standard logistic function to constain it to
be between 0 and 1. The hyperparameters \textbf{hidden\_layer\_size\_d}
and \textbf{hidden\_layer\_size\_g} are unsurprisingly the number of
nodes in the hidden layers of \(D\) and \(G\) respectively. Here we also
define the weights and the biases which define the networks, which are
all initialized to 0.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}d} \PY{o}{=} \PY{l+m+mi}{6}
        \PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}g} \PY{o}{=} \PY{l+m+mi}{5}
        
        \PY{k}{def} \PY{n+nf}{discriminator}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,} \PY{n}{parameters}\PY{p}{)}\PY{p}{:}
            \PY{n}{pre\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{to\PYZus{}float}\PY{p}{(}\PY{n+nb}{input}\PY{p}{)}\PY{p}{,} \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{,} 
                           \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
            \PY{n}{activ\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{pre\PYZus{}1}\PY{p}{)}
            \PY{n}{pre\PYZus{}2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{activ\PYZus{}1}\PY{p}{,} \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{,} 
                           \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)}
            \PY{n}{activ\PYZus{}2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{pre\PYZus{}2}\PY{p}{)}
            \PY{n}{pre\PYZus{}3} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{activ\PYZus{}2}\PY{p}{,} \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{)}\PY{p}{,} 
                           \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
            \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{sigmoid}\PY{p}{(}\PY{n}{pre\PYZus{}3}\PY{p}{)}
            \PY{k}{return} \PY{n}{output}
        
        
        \PY{k}{def} \PY{n+nf}{generator}\PY{p}{(}\PY{n+nb}{input}\PY{p}{,} \PY{n}{parameters}\PY{p}{)}\PY{p}{:}
            \PY{n}{pre\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{to\PYZus{}float}\PY{p}{(}\PY{n+nb}{input}\PY{p}{)}\PY{p}{,} \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}\PY{p}{,} 
                           \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
            \PY{n}{activ\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{pre\PYZus{}1}\PY{p}{)}
            \PY{n}{output} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{matmul}\PY{p}{(}\PY{n}{activ\PYZus{}1}\PY{p}{,} \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}\PY{p}{,} \PY{n}{parameters}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)}
            \PY{k}{return} \PY{n}{output}
        
        \PY{n}{weight\PYZus{}d\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}d}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{bias\PYZus{}d\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}d}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{weight\PYZus{}d\PYZus{}2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}d}\PY{p}{,} \PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}d}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{bias\PYZus{}d\PYZus{}2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}d}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{weight\PYZus{}d\PYZus{}3} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}d}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{bias\PYZus{}d\PYZus{}3} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{d\PYZus{}parameters} \PY{o}{=} \PY{p}{[}\PY{n}{weight\PYZus{}d\PYZus{}1}\PY{p}{,}\PY{n}{bias\PYZus{}d\PYZus{}1}\PY{p}{,} \PY{n}{weight\PYZus{}d\PYZus{}2}\PY{p}{,} \PY{n}{bias\PYZus{}d\PYZus{}2}\PY{p}{,}\PY{n}{weight\PYZus{}d\PYZus{}3}\PY{p}{,} 
                        \PY{n}{bias\PYZus{}d\PYZus{}3}\PY{p}{]}
        
        \PY{n}{weight\PYZus{}g\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}g}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{bias\PYZus{}g\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}g}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{weight\PYZus{}g\PYZus{}2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{n}{hidden\PYZus{}layer\PYZus{}size\PYZus{}g}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{n}{bias\PYZus{}g\PYZus{}2} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{Variable}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{ones}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{g\PYZus{}parameters} \PY{o}{=} \PY{p}{[}\PY{n}{weight\PYZus{}g\PYZus{}1}\PY{p}{,}\PY{n}{bias\PYZus{}g\PYZus{}1}\PY{p}{,} \PY{n}{weight\PYZus{}g\PYZus{}2}\PY{p}{,} \PY{n}{bias\PYZus{}g\PYZus{}2}\PY{p}{]}
\end{Verbatim}


    We now define the losses for \(G\) and \(D\). We first define place
holders \textbf{real\_dist\_placeholder} and
\textbf{generator\_input\_placeholder} which we will use to feed data
into \(G\) and \(D\). We then define the output from \(D\) when it is
judging real and fake samples using the TensorFlow function
\textbf{variable\_scope.reuse\_variables} to ensure that the same
parameters are used for the discriminator when it is inputed a real
sample and a fake sample. The losses are as described in Section XYZ1.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n}{real\PYZus{}dist\PYZus{}placeholder} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n+nb+bp}{None}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{n}{generator\PYZus{}input\PYZus{}placeholder} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{,} \PY{n}{shape}\PY{o}{=}\PY{p}{(}\PY{n+nb+bp}{None}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{variable\PYZus{}scope}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Discriminator}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)} \PY{k}{as} \PY{n}{scope}\PY{p}{:}
            \PY{n}{d\PYZus{}output\PYZus{}real} \PY{o}{=} \PY{n}{discriminator}\PY{p}{(}\PY{n}{real\PYZus{}dist\PYZus{}placeholder}\PY{p}{,} \PY{n}{d\PYZus{}parameters}\PY{p}{)}
            \PY{n}{scope}\PY{o}{.}\PY{n}{reuse\PYZus{}variables}\PY{p}{(}\PY{p}{)}
            \PY{n}{d\PYZus{}output\PYZus{}fake} \PY{o}{=} \PY{n}{discriminator}\PY{p}{(}\PY{n}{generator}\PY{p}{(}\PY{n}{generator\PYZus{}input\PYZus{}placeholder}\PY{p}{,} 
                                                    \PY{n}{g\PYZus{}parameters}\PY{p}{)}\PY{p}{,} \PY{n}{d\PYZus{}parameters}\PY{p}{)}
        \PY{n}{loss\PYZus{}d} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{tf}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{d\PYZus{}output\PYZus{}real}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{tf}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{d\PYZus{}output\PYZus{}fake}\PY{p}{)}\PY{p}{)}
        \PY{n}{loss\PYZus{}g} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{d\PYZus{}output\PYZus{}fake}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    We now create the nessescary parameters for game adaptive learning
rates. Note we make sure the adjustment factor, \textbf{psi}, is less
than zero and the empirical value function, \textbf{V}, is greater than
zero to avoid any rounding errors. The formula for the adjustment
factor, \textbf{psi}, can be found in Appendix XYZ2.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{phi\PYZus{}g} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
        \PY{n}{phi\PYZus{}d} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
        \PY{n}{gamma\PYZus{}g} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
        \PY{n}{gamma\PYZus{}d} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{placeholder}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
        \PY{n}{psi\PYZus{}1} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{p}{(}\PY{n}{gamma\PYZus{}d} \PY{o}{\PYZhy{}} \PY{n}{gamma\PYZus{}g} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{l+m+mi}{2}\PY{o}{*}\PY{n}{phi\PYZus{}g}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{phi\PYZus{}d}\PY{p}{)}\PY{o}{/}
                       \PY{p}{(}\PY{o}{\PYZhy{}}\PY{n}{gamma\PYZus{}d}\PY{o}{+}\PY{n}{gamma\PYZus{}g}\PY{o}{\PYZhy{}}\PY{n}{phi\PYZus{}d}\PY{p}{)}\PY{p}{)}\PY{o}{/}\PY{n}{tf}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{l+m+mf}{16.0}\PY{p}{)}
        \PY{n}{psi} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{maximum}\PY{p}{(}\PY{l+m+mf}{0.0}\PY{p}{,} \PY{n}{psi\PYZus{}1}\PY{p}{)}
        
        \PY{n}{V} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{minimum}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{reduce\PYZus{}mean}\PY{p}{(}\PY{n}{tf}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{d\PYZus{}output\PYZus{}real}\PY{p}{)}\PY{o}{+}
                                      \PY{n}{tf}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{l+m+mi}{1}\PY{o}{\PYZhy{}}\PY{n}{d\PYZus{}output\PYZus{}fake}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{n}{learning\PYZus{}rate\PYZus{}d} \PY{o}{=} \PY{n}{gamma\PYZus{}d}\PY{o}{\PYZhy{}}\PY{n}{phi\PYZus{}d}\PY{o}{*}\PY{n}{tf}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{psi}\PY{o}{*}\PY{n}{V}\PY{p}{)}
        \PY{n}{learning\PYZus{}rate\PYZus{}g} \PY{o}{=} \PY{n}{gamma\PYZus{}g} \PY{o}{+} \PY{n}{phi\PYZus{}g}\PY{o}{*}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{+} \PY{n}{tf}\PY{o}{.}\PY{n}{tanh}\PY{p}{(}\PY{n}{psi}\PY{o}{*}\PY{n}{V}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    We now define the training steps:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{train\PYZus{}g} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{GradientDescentOptimizer}\PY{p}{(}\PY{n}{learning\PYZus{}rate\PYZus{}g}\PY{p}{)}\PY{o}{.}\PYZbs{}
                                \PY{n}{minimize}\PY{p}{(}\PY{n}{loss\PYZus{}g}\PY{p}{,} \PY{n}{var\PYZus{}list}\PY{o}{=}\PY{n}{g\PYZus{}parameters}\PY{p}{)}
        \PY{n}{train\PYZus{}d} \PY{o}{=} \PY{n}{tf}\PY{o}{.}\PY{n}{train}\PY{o}{.}\PY{n}{GradientDescentOptimizer}\PY{p}{(}\PY{n}{learning\PYZus{}rate\PYZus{}d}\PY{p}{)}\PY{o}{.}\PYZbs{}
                                \PY{n}{minimize}\PY{p}{(}\PY{n}{loss\PYZus{}d}\PY{p}{,} \PY{n}{var\PYZus{}list}\PY{o}{=}\PY{n}{d\PYZus{}parameters}\PY{p}{)}
\end{Verbatim}


    After the training iterations we will save the final generated
distribution to file in order to anaylse. Therefore we create a matrix
to store these reuslts in. Recall \textbf{gamma\_vec} and
\textbf{phi\_vec} hold the values of \(\phi\) and \(\gamma\) we will be
using in the sixteen simulations. In each combination of \(\phi\) and
\(\gamma\) we first open a TensorFlow session and initalize the
variables. We then perform the learning steps. Finally we create a
generated batch to export.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{res\PYZus{}matrix} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{gamma\PYZus{}vec}\PY{p}{)} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{phi\PYZus{}vec}\PY{p}{)}\PY{p}{,} \PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{)}
        \PY{n}{gamma\PYZus{}out\PYZus{}vec}\PY{p}{,} \PY{n}{phi\PYZus{}out\PYZus{}vec} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{gamma\PYZus{}vec}\PY{p}{)} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{phi\PYZus{}vec}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{,}\PYZbs{}
        \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{gamma\PYZus{}vec}\PY{p}{)} \PY{o}{*} \PY{n+nb}{len}\PY{p}{(}\PY{n}{phi\PYZus{}vec}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{row} \PY{o}{=}\PY{l+m+mi}{0} \PY{c+c1}{\PYZsh{} This indexes which row of res\PYZus{}matrix we are writing to.}
        \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{p} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{phi\PYZus{}vec}\PY{p}{)}\PY{p}{:}
            \PY{k}{for} \PY{n}{j}\PY{p}{,} \PY{n}{k} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{gamma\PYZus{}vec}\PY{p}{)}\PY{p}{:}
                \PY{k}{with} \PY{n}{tf}\PY{o}{.}\PY{n}{Session}\PY{p}{(}\PY{p}{)} \PY{k}{as} \PY{n}{sess}\PY{p}{:}
                    \PY{n}{tf}\PY{o}{.}\PY{n}{global\PYZus{}variables\PYZus{}initializer}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{p}{)}
                    \PY{k}{for} \PY{n}{step} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{number\PYZus{}of\PYZus{}epochs}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
                        \PY{n}{generator\PYZus{}input} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} 
                                                            \PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                        \PY{n}{real\PYZus{}dist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{real\PYZus{}mean}\PY{p}{,} \PY{n}{real\PYZus{}sd}\PY{p}{,} 
                                                             \PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        
                        \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{train\PYZus{}d}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{real\PYZus{}dist\PYZus{}placeholder}\PY{p}{:} 
                                                     \PY{n}{real\PYZus{}dist}\PY{p}{,}
                                                     \PY{n}{generator\PYZus{}input\PYZus{}placeholder}\PY{p}{:} 
                                                     \PY{n}{generator\PYZus{}input}\PY{p}{,} 
                                                     \PY{n}{phi\PYZus{}g}\PY{p}{:} \PY{n}{p}\PY{p}{,}\PY{n}{phi\PYZus{}d}\PY{p}{:}\PY{n}{p}\PY{p}{,} 
                                                     \PY{n}{gamma\PYZus{}g}\PY{p}{:}\PY{n}{k}\PY{p}{,}\PY{n}{gamma\PYZus{}d}\PY{p}{:}\PY{n}{k} \PY{p}{\PYZcb{}}\PY{p}{)}
                        \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{train\PYZus{}g}\PY{p}{,} \PY{n}{feed\PYZus{}dict}\PY{o}{=}\PY{p}{\PYZob{}}\PY{n}{real\PYZus{}dist\PYZus{}placeholder}\PY{p}{:} 
                                                     \PY{n}{real\PYZus{}dist}\PY{p}{,}
                                                     \PY{n}{generator\PYZus{}input\PYZus{}placeholder}\PY{p}{:} 
                                                     \PY{n}{generator\PYZus{}input}\PY{p}{,} 
                                                     \PY{n}{phi\PYZus{}g}\PY{p}{:} \PY{n}{p}\PY{p}{,}\PY{n}{phi\PYZus{}d}\PY{p}{:}\PY{n}{p}\PY{p}{,} 
                                                     \PY{n}{gamma\PYZus{}g}\PY{p}{:}\PY{n}{k}\PY{p}{,}\PY{n}{gamma\PYZus{}d}\PY{p}{:}\PY{n}{k} \PY{p}{\PYZcb{}}\PY{p}{)}
                        
                    \PY{n}{generator\PYZus{}input} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                    \PY{n}{real\PYZus{}dist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{real\PYZus{}mean}\PY{p}{,} \PY{n}{real\PYZus{}sd}\PY{p}{,} \PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
        
                    \PY{n}{generated} \PY{o}{=} \PY{n}{sess}\PY{o}{.}\PY{n}{run}\PY{p}{(}\PY{n}{generator}\PY{p}{(}\PY{n}{generator\PYZus{}input}\PY{p}{,}\PY{n}{g\PYZus{}parameters}\PY{p}{)}\PY{p}{)}
                    \PY{n}{res\PYZus{}matrix}\PY{p}{[}\PY{n}{row}\PY{p}{]} \PY{o}{=} \PY{n}{generated}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}
                    \PY{n}{gamma\PYZus{}out\PYZus{}vec}\PY{p}{[}\PY{n}{row}\PY{p}{]} \PY{o}{=} \PY{n}{k}
                    \PY{n}{phi\PYZus{}out\PYZus{}vec}\PY{p}{[}\PY{n}{row}\PY{p}{]} \PY{o}{=} \PY{n}{p}
                    \PY{n}{row} \PY{o}{=} \PY{n}{row} \PY{o}{+} \PY{l+m+mi}{1} 
\end{Verbatim}


    After we have iterated through these sixteen \((\phi, \gamma)\)
combinations we save the ouput to file, the resulting data has
\(\gamma\) in the first column, \(\phi\) in the second and then the 1000
generated samples in columns 3 to 1002.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{res\PYZus{}dataframe} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{res\PYZus{}matrix}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{float}\PY{p}{)}\PY{p}{)}
        \PY{n}{gamma\PYZus{}dataframe} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{gamma\PYZus{}out\PYZus{}vec}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{float}\PY{p}{)}\PY{p}{)}
        \PY{n}{phi\PYZus{}dataframe} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{phi\PYZus{}out\PYZus{}vec}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{float}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{output\PYZus{}dataframe1} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{gamma\PYZus{}dataframe}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}\PY{p}{,} 
                                       \PY{n}{phi\PYZus{}dataframe}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        \PY{n}{output\PYZus{}dataframe2} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{output\PYZus{}dataframe1}\PY{o}{.}\PY{n}{reset\PYZus{}index}\PY{p}{(}\PY{n}{drop}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}\PY{p}{,} 
                                       \PY{n}{res\PYZus{}dataframe}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{output.csv}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{a}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{f}\PY{p}{:}
            \PY{n}{output\PYZus{}dataframe2}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{n}{f}\PY{p}{,} \PY{n}{sep}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{,}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{float\PYZus{}format}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}.9f}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                                     \PY{n}{index}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
